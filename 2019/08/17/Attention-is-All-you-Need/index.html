<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  
  
    <meta name="keywords" content="CS_learn, Keep Moving...">
  
  
    <meta name="description" content="The Space to record knowledge and my life.">
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <title>
    Attention is All you Need |
    
    Kelly&#39;s Blogs</title>
  
    <link rel="shortcut icon" href="/favicon.ico">
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<script src="/js/pace.min.js"></script>

<meta name="generator" content="Hexo 4.2.0"></head>

<body>
<main class="content">
  <section class="outer">
  <article id="post-Attention-is-All-you-Need" class="article article-type-post" itemscope itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Attention is All you Need
    </h1>
  
  




      </header>
    

    
      <div class="article-meta">
        <a href="/2019/08/17/Attention-is-All-you-Need/" class="article-date">
  <time datetime="2019-08-17T01:35:38.000Z" itemprop="datePublished">2019-08-17</time>
</a>
        
  <div class="article-category">
    <a class="article-category-link" href="/categories/NLP/">NLP</a>
  </div>

      </div>
    

    <div class="article-entry" itemprop="articleBody">
      

      

      
        <p>简单来说，Attention 可以理解为表示重要性的权重向量</p>
<p>为了预测或推断一个元素，使用<strong>注意力权重</strong>来估计其它元素与其相关的强度，并由<strong>注意力权重加权的值的总和</strong>作为计算最终目标的特征。</p>
<ul>
<li>step 1：计算其它元素与待预测元素的相关性权重</li>
<li>step 2：根据相关性权重对其他元素进行加权求和</li>
</ul>
<h4 id="Attention-机制"><a href="#Attention-机制" class="headerlink" title="Attention 机制"></a>Attention 机制</h4><p>对Encoder层状态的加权</p>
<p><img src="/2019/08/17/Attention-is-All-you-Need/Attention.jpg" alt="img"></p>
<h4 id="Seq2Seq"><a href="#Seq2Seq" class="headerlink" title="Seq2Seq"></a>Seq2Seq</h4><p>对于一个输入序列，我们需要将其转化为一个新的输出序列，其中输入、输出序列的长度可以是任意的长度</p>
<ul>
<li>机器翻译</li>
<li>问答系统</li>
<li>语音识别</li>
</ul>
<p>使用 Encoder-Decoder 框架 </p>
<p>Sutskever  et al., Sequence to sequence learning with neural networks. 2014</p>
<p>Bahdanau et al.,  (2014). Neural machine translation by jointly learning to align and translate</p>
<h4 id="Self-Attention"><a href="#Self-Attention" class="headerlink" title="Self Attention"></a>Self Attention</h4><p>一个序列之间自己做 attention ，每一个词的 embedding 产生一个q vector，k vector，v vector,  用 q 去匹配每一个 k（计算dot-product)，通过一个 softmax 映射为权重，再与 v 相乘，求和（这一步可以看做加权求和，就是 attention 的思想），得到最终的表示 z 。</p>
<p><img src="/2019/08/17/Attention-is-All-you-Need/self-attention.png" alt="img"></p>
<h4 id="Multi-head-Attention"><a href="#Multi-head-Attention" class="headerlink" title="Multi-head Attention"></a>Multi-head Attention</h4><p>生成多组 （Q，K，V）分别进行 self-attention 计算，将最后得到的多个 z 进行拼接。好处是多个 head 可以捕获不同的特征</p>
<p><img src="/2019/08/17/Attention-is-All-you-Need/transformer_multi-headed_self-attention-recap.png" alt="img"></p>
<h4 id="模型架构"><a href="#模型架构" class="headerlink" title="模型架构"></a>模型架构</h4><p><img src="/2019/08/17/Attention-is-All-you-Need/transformer_resideual_layer_norm_3.png" alt="img"></p>
<p><strong>PS</strong>：<br>Transformer 重点是如何做self-attention，其中 Q, K, V的计算比较重要，解释这篇论文比较好的博客有：</p>
<p><a href="http://jalammar.github.io/illustrated-transformer/" target="_blank" rel="noopener" title="The Illustrated Transformer">The Illustrated Transformer</a><br><a href="https://zhuanlan.zhihu.com/p/39034683" target="_blank" rel="noopener" title="Transformer模型笔记">Transformer模型笔记</a></p>
<p>论文来自:</p>
<p><a href="https://arxiv.org/pdf/1706.03762.pdf" target="_blank" rel="noopener" title="Attention Is All You Need">Attention Is All You Need</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://tiantianliu2018.github.io/2019/08/17/Attention-is-All-you-Need/" data-id="ckf6s580a0001xptt55604p0m"
         class="article-share-link">Share</a>
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Attention/" rel="tag">Attention</a></li></ul>

    </footer>

  </div>

  
    
  <nav class="article-nav">
    
      <a href="/2019/08/17/Seq2Seq-Learning-with-Nerual-Network-code/" class="article-nav-link">
        <strong class="article-nav-caption">Newer posts</strong>
        <div class="article-nav-title">
          
            Seq2Seq-Learning-with-Nerual-Network-code
          
        </div>
      </a>
    
    
      <a href="/2019/08/16/%E7%89%9B%E9%A1%BF%E6%B1%82%E6%A0%B9%E6%B3%95/" class="article-nav-link">
        <strong class="article-nav-caption">Olde posts</strong>
        <div class="article-nav-title">牛顿求根法</div>
      </a>
    
  </nav>


  

  
    
  

</article>



</section>
  <footer class="footer">
  <div class="outer">
    <div class="float-right">
      <ul class="list-inline">
  
    <li><i class="fe fe-smile-alt"></i> <span id="busuanzi_value_site_uv"></span></li>
  
</ul>
    </div>
    <ul class="list-inline">
      <li>&copy; 2020 Kelly&#39;s Blogs</li>
      <li>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a></li>
      <li>Theme  <a href="https://github.com/zhwangart/hexo-theme-ocean" target="_blank" rel="noopener">Ocean</a></li>
    </ul>
  </div>
</footer>

</main>
<aside class="sidebar">
  <button class="navbar-toggle"></button>

<nav class="navbar">
  
    <div class="logo">
      <a href="/"><img src="/images/hexo.svg" alt="Kelly&#39;s Blogs"></a>
    </div>
  
  <ul class="nav nav-main">
    
      <li class="nav-item">
        <a class="nav-item-link" href="/">Home</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-item-link" href="/archives">Archives</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-item-link" href="/gallery">Gallery</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-item-link" href="/about">About</a>
      </li>
    
    <li class="nav-item">
      <a class="nav-item-link nav-item-search" title="搜索">
        <i class="fe fe-search"></i>
        Search
      </a>
    </li>
  </ul>
</nav>

<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      <div class="totop" id="totop">
  <i class="fe fe-rocket"></i>
</div>
    </li>
    <li class="nav-item">
      
        <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
          <i class="fe fe-feed"></i>
        </a>
      
    </li>
  </ul>
</nav>

<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
</aside>

<script src="/js/jquery-2.0.3.min.js"></script>


<script src="/js/lazyload.min.js"></script>


<script src="/js/snap.svg-min.js"></script>


<script src="/js/busuanzi-2.3.pure.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>






<script src="/js/ocean.js"></script>


</body>
</html>