<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  
  
    <meta name="keywords" content="CS_learn, Keep Moving...">
  
  
    <meta name="description" content="The Space to record knowledge and my life.">
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <title>
    Spark 学习笔记 |
    
    Kelly&#39;s Blogs</title>
  
    <link rel="shortcut icon" href="/favicon.ico">
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<script src="/js/pace.min.js"></script>

<meta name="generator" content="Hexo 4.2.0"></head>

<body>
<main class="content">
  <section class="outer">
  <article id="post-Spark-学习笔记" class="article article-type-post" itemscope itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Spark 学习笔记
    </h1>
  
  




      </header>
    

    
      <div class="article-meta">
        <a href="/2020/06/12/Spark-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" class="article-date">
  <time datetime="2020-06-12T02:00:54.000Z" itemprop="datePublished">2020-06-12</time>
</a>
        
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a>
  </div>

      </div>
    

    <div class="article-entry" itemprop="articleBody">
      

      

      
        <h1 id="Spark-学习笔记"><a href="#Spark-学习笔记" class="headerlink" title="Spark 学习笔记"></a>Spark 学习笔记</h1><hr>
<h2 id="一、Spark-简介"><a href="#一、Spark-简介" class="headerlink" title="一、Spark 简介"></a>一、Spark 简介</h2><p>基于<strong>内存计算</strong>的大数据<strong>并行计算框架</strong></p>
<p>特点：</p>
<ul>
<li>速度快</li>
<li>易用</li>
<li>通用</li>
<li>运行模式多样</li>
</ul>
<a id="more"></a>
<h2 id="二、Spark-生态系统"><a href="#二、Spark-生态系统" class="headerlink" title="二、Spark 生态系统"></a>二、Spark 生态系统</h2><h2 id="三、Spark-运行架构"><a href="#三、Spark-运行架构" class="headerlink" title="三、Spark 运行架构"></a>三、Spark 运行架构</h2><p>RDD：Resillient Distributed Dataset（弹性分布式数据集）共享内存模型</p>
<p>DAG：有向无环图  反映 RDD 之间的依赖关系</p>
<p>Executor：运行在工作节点的一个进程，负责运行 Task</p>
<p>Application：用户编写的 Spark 应用程序</p>
<p>Task：运行在 Executor 上的工作单元</p>
<p>Job：一个 Job 包含多个 RDD 及作用于相应 RDD 上的各种操作</p>
<p>Stage：是 Job 的基本调度单位，一个 Job 会分为多组 Task，每组 Task 被称为 Stage，或者也被称为 TaskSet，代表了一组关联的、相互之间没有 Shuffle 依赖关系的任务组成的任务集</p>
<p><img src="/2020/06/12/Spark-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/spark.png" alt="Spark 运行架构"></p>
<h3 id="Spark-运行基本流程"><a href="#Spark-运行基本流程" class="headerlink" title="Spark 运行基本流程"></a>Spark 运行基本流程</h3><p><img src="/2020/06/12/Spark-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/run.png" alt="Spark 基本运行流程"></p>
<p>RDD 在 Spark 中的运行过程：</p>
<ol>
<li><p>创建 RDD 对象</p>
</li>
<li><p>SparkContext 负责计算 RDD 时间的依赖关系，构建DAG</p>
</li>
<li><p>DAGScheduler 负责把 DAG 图分解成多个 Stage， 每个 Stage 中包含了多个 Task，每个 Task 会 TaskScheduler</p>
<p>分发给各个 WorkerNode 上的 Executor 去执行</p>
</li>
</ol>
<h2 id="四、RDD-编程"><a href="#四、RDD-编程" class="headerlink" title="四、RDD 编程"></a>四、RDD 编程</h2><h3 id="1-RDD-创建"><a href="#1-RDD-创建" class="headerlink" title="1. RDD 创建"></a>1. RDD 创建</h3><ul>
<li><p>从文件系统中加载数据创建</p>
<p><code>sc.textFile(&quot;file:///&quot;)</code> 本地文件系统</p>
<p><code>sc.textFile(&quot;hdfs://地址&quot;)</code> 分布式文件系统 HDFS</p>
</li>
<li><p>通过并行集合（数组）创建 RDD</p>
<p><code>sc.parallelize()</code></p>
</li>
</ul>
<h3 id="2-RDD-操作-惰性求值"><a href="#2-RDD-操作-惰性求值" class="headerlink" title="2. RDD 操作 惰性求值"></a>2. RDD 操作 惰性求值</h3><h4 id="转换操作"><a href="#转换操作" class="headerlink" title="转换操作"></a>转换操作</h4><p>filter：筛选、map：映射、flatMap、groupByKey()、reduceByKey()</p>
<h4 id="行动操作-真正触发计算"><a href="#行动操作-真正触发计算" class="headerlink" title="行动操作  真正触发计算"></a>行动操作  真正触发计算</h4><p><code>count()</code> 返回数据集中的元素个数 </p>
<p><code>collect()</code> 以<strong>数组</strong>的形式返回数据集中的所有元素 </p>
<p><code>first()</code> 返回数据集中的第一个元素 </p>
<p><code>take(n)</code> 以数组的形式返回数据集中的前n个元素 </p>
<p><code>reduce(func)</code> 通过函数 func（输入两个参数并返回一个值） 聚合数据集中的元素</p>
<p><code>foreach(func)</code> 将数据集中的每个元素传递到函数func中运行</p>
<h3 id="3-RDD-持久化"><a href="#3-RDD-持久化" class="headerlink" title="3. RDD 持久化"></a>3. RDD 持久化</h3><h3 id="4-RDD-分区"><a href="#4-RDD-分区" class="headerlink" title="4. RDD 分区"></a>4. RDD 分区</h3><h3 id="5-键值对-RDD"><a href="#5-键值对-RDD" class="headerlink" title="5. 键值对 RDD"></a>5. 键值对 RDD</h3><p><code>reduceByKey(func)</code> 使用 func 函数合并具有相同键的值，用于对每个 key 对应的多个 value 进行 merge 操作，最重要的是它能够在本地先进行 merge 操作，并且 merge 操作可以通过函数自定义</p>
<p><code>groupByKey()</code> 对具有相同 key 的 value 进行分组，但只生成一个 sequence，groupByKey 本身不能自定义函数，需要先用 groupByKey 生成 RDD，然后才能对此 RDD 通过 map 进行自定义函数操作</p>
<p><code>keys</code>只会把 Pair RDD 中的 key 返回形成一个新的 RDD</p>
<p><code>values</code>  只会把 Pair RDD中 的 value 返回形成一个新的 RDD。</p>
<p><code>sortByKey()</code> 返回一个根据键排序的 RDD，默认是升序排序</p>
<p><code>mapValues(func)</code> 对键值对 RDD 中的每个 value 都应用一个函数，但是，key 不会发生变化</p>
<p><code>join</code> 内连接，只有在两个数据集中都存在的 key 才会被输出，最终得到一个 (K,(V1,V2)) 类型的数据集。</p>
<p><code>combineByKey(createCombiner,mergeValue,mergeCombiners,partitioner ,mapSideCombine)</code></p>
<h3 id="6-共享变量"><a href="#6-共享变量" class="headerlink" title="6. 共享变量"></a>6. 共享变量</h3><p>广播变量：把变量在所有节点的内存之间进行共享。缓存一个只读变量</p>
<p>​    通过调用 <code>SparkContext.broadcast(v)</code> 来从一个普通变量 v 中创建一个广播变量</p>
<p>​    通过调用 <code>value</code> 方法就可以获得这个广播变量的值，</p>
<p>累加器：支持在所有不同节点之间进行累加计算</p>
<p>​    通过调用 <code>SparkContext.longAccumulator()</code> 或者 <code>SparkContext.doubleAccumulator()</code> 来创建</p>
<p>​    只有任务控制节点（Driver Program）可以使用 <code>value</code> 方法来读取累加器的值</p>
<h3 id="7-数据读写"><a href="#7-数据读写" class="headerlink" title="7. 数据读写"></a>7. 数据读写</h3><h4 id="本地文件数据的读写"><a href="#本地文件数据的读写" class="headerlink" title="本地文件数据的读写"></a>本地文件数据的读写</h4><p><code>sc.textFile()</code>  惰性机制，行动操作才进行加载</p>
<p><code>saveAsTextFile()</code>  生成一个目录  part-00000  RDD 分区，再次加载只需要写这个目录</p>
<h4 id="分布式文件系统读写"><a href="#分布式文件系统读写" class="headerlink" title="分布式文件系统读写"></a>分布式文件系统读写</h4><p><code>sc.textFile(&quot;hdfs://&quot;)</code></p>
<h4 id="JSON-文件读写"><a href="#JSON-文件读写" class="headerlink" title="JSON 文件读写"></a>JSON 文件读写</h4><p><code>sc.textFile()</code></p>
<p>对 json 进行解析 scala.util.parsing.json.Json 可以实现对 JSON 数据的解析</p>
<h3 id="8-HBase"><a href="#8-HBase" class="headerlink" title="8. HBase"></a>8. HBase</h3><p>HBase 中需要根据行键、列族、列限定符和时间戳来确定一个单元格</p>
<p>HBase 需要时间戳是因为 HBAse 的底层是 HDFS，HDFS 要求一次写入不能进行修改，所以要修改单元格的数据只能生成新的版本，让最新的数指向最新的版本</p>
<p>四维坐标定位【行键、列族、列、版本时间戳】</p>
<p>一个单元格一个插入数据</p>
<h2 id="五、Spark-SQL"><a href="#五、Spark-SQL" class="headerlink" title="五、Spark SQL"></a>五、Spark SQL</h2><p>RDD 是分布式的 Java 对象的集合</p>
<p>DataFrame 是一种以 RDD 为基础的分布式数据集</p>
<p><code>spark.read.json()</code> 读取 json 文件</p>
<p><code>spark.read.parquet(&quot;people.parquet&quot;)</code> </p>
<p><code>spark.read.csv(&quot;people.csv&quot;)</code></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://tiantianliu2018.github.io/2020/06/12/Spark-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" data-id="ckf6s581u003qxpttfrjf5oxa"
         class="article-share-link">Share</a>
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/" rel="tag">Spark</a></li></ul>

    </footer>

  </div>

  
    
  <nav class="article-nav">
    
      <a href="/2020/06/19/Maven-%E5%88%9B%E5%BB%BA-Spark-%E9%A1%B9%E7%9B%AE%E9%87%87%E5%9D%91%E8%AE%B0%E5%BD%95/" class="article-nav-link">
        <strong class="article-nav-caption">Newer posts</strong>
        <div class="article-nav-title">
          
            Maven 创建 Spark 项目采坑记录
          
        </div>
      </a>
    
    
      <a href="/2020/04/24/HBase-%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93/" class="article-nav-link">
        <strong class="article-nav-caption">Olde posts</strong>
        <div class="article-nav-title">HBase 基础总结</div>
      </a>
    
  </nav>


  

  
    
  

</article>



</section>
  <footer class="footer">
  <div class="outer">
    <div class="float-right">
      <ul class="list-inline">
  
    <li><i class="fe fe-smile-alt"></i> <span id="busuanzi_value_site_uv"></span></li>
  
</ul>
    </div>
    <ul class="list-inline">
      <li>&copy; 2020 Kelly&#39;s Blogs</li>
      <li>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a></li>
      <li>Theme  <a href="https://github.com/zhwangart/hexo-theme-ocean" target="_blank" rel="noopener">Ocean</a></li>
    </ul>
  </div>
</footer>

</main>
<aside class="sidebar">
  <button class="navbar-toggle"></button>

<nav class="navbar">
  
    <div class="logo">
      <a href="/"><img src="/images/hexo.svg" alt="Kelly&#39;s Blogs"></a>
    </div>
  
  <ul class="nav nav-main">
    
      <li class="nav-item">
        <a class="nav-item-link" href="/">Home</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-item-link" href="/archives">Archives</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-item-link" href="/gallery">Gallery</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-item-link" href="/about">About</a>
      </li>
    
    <li class="nav-item">
      <a class="nav-item-link nav-item-search" title="搜索">
        <i class="fe fe-search"></i>
        Search
      </a>
    </li>
  </ul>
</nav>

<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      <div class="totop" id="totop">
  <i class="fe fe-rocket"></i>
</div>
    </li>
    <li class="nav-item">
      
        <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
          <i class="fe fe-feed"></i>
        </a>
      
    </li>
  </ul>
</nav>

<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
</aside>

<script src="/js/jquery-2.0.3.min.js"></script>


<script src="/js/lazyload.min.js"></script>


<script src="/js/snap.svg-min.js"></script>


<script src="/js/busuanzi-2.3.pure.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>






<script src="/js/ocean.js"></script>


</body>
</html>