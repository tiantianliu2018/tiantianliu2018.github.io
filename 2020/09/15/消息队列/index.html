<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  
  
    <meta name="keywords" content="CS_learn, Keep Moving...">
  
  
    <meta name="description" content="The Space to record knowledge and my life.">
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <title>
    消息队列 |
    
    Kelly&#39;s Blogs</title>
  
    <link rel="shortcut icon" href="/favicon.ico">
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<script src="/js/pace.min.js"></script>

<meta name="generator" content="Hexo 4.2.0"></head>

<body>
<main class="content">
  <section class="outer">
  <article id="post-消息队列" class="article article-type-post" itemscope itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      消息队列
    </h1>
  
  




      </header>
    

    
      <div class="article-meta">
        <a href="/2020/09/15/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/" class="article-date">
  <time datetime="2020-09-15T13:40:39.000Z" itemprop="datePublished">2020-09-15</time>
</a>
        
  <div class="article-category">
    <a class="article-category-link" href="/categories/Java/">Java</a>
  </div>

      </div>
    

    <div class="article-entry" itemprop="articleBody">
      

      

      
        <h1 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a>消息队列</h1><p>实习过程中用到了 kafka 作为消息队列，但是对于 kafka 的了解并不是特别多，特别学习部分内容作为记录。</p>
<h2 id="消息队列的优缺点"><a href="#消息队列的优缺点" class="headerlink" title="消息队列的优缺点"></a>消息队列的优缺点</h2><p>优点：解耦，异步，削峰</p>
<p>缺点：系统可用性降低，系统复杂度提高（消息重复消费、消息丢失、消息传递的顺序性），一致性问题</p>
<a id="more"></a>
<h2 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h2><h3 id="1-定义"><a href="#1-定义" class="headerlink" title="1. 定义"></a>1. 定义</h3><p>Apache Kafka是由 Apache 开发的一种<strong>发布订阅消息系统</strong>，它是一个<strong>分布式的、分区的和可复制的</strong>提交日志服务。</p>
<p><strong>应用</strong>：</p>
<ul>
<li>消息队列</li>
<li>数据处理：构建实时流处理程序来转换或处理数据流</li>
</ul>
<h3 id="2-Kafka-消息模型"><a href="#2-Kafka-消息模型" class="headerlink" title="2. Kafka 消息模型"></a>2. Kafka 消息模型</h3><p>发布订阅消息模型</p>
<p><img src="/2020/09/15/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/kafka artitec.png" alt="kafka 架构模型"></p>
<p><strong>Producer：消息发送者</strong>。负责将消息发送到 Kafka 集群的某一个 topic 中。</p>
<p><strong>Consumer：消息消费者</strong>。订阅 topic，获取消息。</p>
<p><strong>Broker：Kafka 集群中的每一台服务器</strong>。Kafka 是一个分布式集群，其中每一台服务器都叫做 Broker。</p>
<p><strong>Topic</strong>：属于特定类别的消息流称为主题。可以理解为消息的标签🏷，订阅了该 topic 的消费者会接收到所有该类消息。</p>
<p><strong>Partition</strong>：分区，属于 Topic 的一部分，一个 Topic 可以有多个 Partition，同一 Topic 下的 Partition 可以分布在不同的 Broker 上。</p>
<h3 id="3-Kafka-工作流程及文件存储机制"><a href="#3-Kafka-工作流程及文件存储机制" class="headerlink" title="3. Kafka 工作流程及文件存储机制"></a>3. Kafka 工作流程及文件存储机制</h3><h4 id="kafka-工作流程"><a href="#kafka-工作流程" class="headerlink" title="kafka 工作流程"></a>kafka 工作流程</h4><p><img src="/2020/09/15/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/produce.png" alt="工作流程"></p>
<p>Kafka 中消息是以 topic 进行分类的，生产者生产消息，消费者消费消息，都是面向 topic 的。<br>topic 是逻辑上的概念，而 partition 是物理上的概念，每个 partition 对应于一个 log 文件，该 log 文件中存储的就是 producer 生产的数据。Producer 生产的数据会被不断追加到该 log 文件末端，且每条数据都有自己的 <strong>offset</strong>。消费者组中的每个消费者，都会实时记录自己消费到了哪个 offset，以便出错恢复时，从上次的位置继续消费。</p>
<h4 id="Kafka-文件存储机制"><a href="#Kafka-文件存储机制" class="headerlink" title="Kafka 文件存储机制"></a>Kafka 文件存储机制</h4><p><img src="/2020/09/15/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/file.png" alt="file"></p>
<p>生产者生产的消息会不断追加到 log 文件末尾，为防止 log 文件过大导致数据定位效率低下，Kafka 采取了分片和索引机制，将每个 partition 分为多个 segment。每个 segment 对应两个文件——“.index” 文件和 “.log” 文件。这些文件位于一个文件夹下，该文件夹的命名规则为：topic名称 + 分区序号。例如，这个 topic 有三个分区，则其对应的文件夹为 topic-0, topic-1, topic-2。</p>
<p> index 和 log 文件以当前 segment 的第一条消息的 offset 命名。下图为 index 文件和 log 文件的结构示意图。</p>
<p><img src="/2020/09/15/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/index文件和log文件的结构示意图.jpg" alt="index文件和log文件的结构示意图"></p>
<p><strong>“.index” 文件存储大量的索引信息，“.log”文件存储大量的数据</strong>，索引文件中的元数据指向对应数据文件中 message 的物理偏移地址。</p>
<h3 id="4-Kafka-消息可靠传递"><a href="#4-Kafka-消息可靠传递" class="headerlink" title="4. Kafka 消息可靠传递"></a>4. Kafka 消息可靠传递</h3><h4 id="4-1-Kafka-顺序消费"><a href="#4-1-Kafka-顺序消费" class="headerlink" title="4.1 Kafka 顺序消费"></a>4.1 Kafka 顺序消费</h4><p>Kafaka 能够保证<strong>一个 Partition 中的消息有序</strong>（消息被追加到 Partition 的时候，会有一个特定的偏移量 offset，Kafaka 通过偏移量保证消息在分区内的顺序性）。一个 Topic 对应多个 Partition，<strong>Kafaka 不能保证多个 Partition 有序。</strong></p>
<p><strong>解决方法</strong>：</p>
<ol>
<li>一个 Topic 对应一个 Partition</li>
<li>发送消息的时候，指定 key/partition，让同一个 key 的消息发送到同一个 partition</li>
</ol>
<h4 id="4-2-Kafka-如何保证消息不丢失"><a href="#4-2-Kafka-如何保证消息不丢失" class="headerlink" title="4.2 Kafka 如何保证消息不丢失"></a>4.2 Kafka 如何保证消息不丢失</h4><h5 id="消费端丢失数据"><a href="#消费端丢失数据" class="headerlink" title="消费端丢失数据"></a>消费端丢失数据</h5><p>在 consumer 消费阶段，对 offset 的处理，关系到是否丢失数据。<strong>如果在消息处理完成前就提交了offset，那么就有可能造成数据的丢失。</strong></p>
<p>Kafka 会自动提交 offset，那么只要<strong>关闭自动提交</strong> offset，<code>enable.auto.commit=false</code>，在处理完之后自己手动提交 offset，就可以保证数据不会丢。</p>
<h5 id="Kafka-丢失数据"><a href="#Kafka-丢失数据" class="headerlink" title="Kafka 丢失数据"></a>Kafka 丢失数据</h5><p>Kafka 某个 broker 宕机，然后重新选举 partition 的 leader。若此时其他的 follower 还有数据没有进行同步，此时 leader 挂了，选举某个 follower 成 leader 之后，就会丢失一些数据。</p>
<p>所以此时一般是要求起码设置如下 4 个参数：</p>
<ul>
<li>给 topic 设置 <code>replication.factor</code> 参数：这个值必须大于 1，要求每个 partition 必须有至少 2 个副本。</li>
<li>在 Kafka 服务端设置 <code>min.insync.replicas</code> 参数：这个值必须大于 1，这个是要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower。</li>
<li>在 producer 端设置 <code>acks=all</code> ：这个是要求每条数据，必须是<strong>写入所有 replica 之后，才能认为是写成功了</strong>。</li>
<li>在 producer 端设置 <code>retries=MAX</code> （很大很大很大的一个值，无限次重试的意思）：这个是<strong>要求一旦写入失败，就无限重试</strong>，卡在这里了。</li>
</ul>
<p>这样配置之后，至少在 Kafka broker 端就可以保证在 leader 所在 broker 发生故障，进行 leader 切换时，数据不会丢失。</p>
<h5 id="生产者丢失数据"><a href="#生产者丢失数据" class="headerlink" title="生产者丢失数据"></a>生产者丢失数据</h5><p>若设置好了 kafka，<code>acks=all</code> ，一定不会丢。此时要求 leader 接收到消息，所有的 follower 都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。</p>
<h4 id="4-3-Kafka-如何保证不重复消费？"><a href="#4-3-Kafka-如何保证不重复消费？" class="headerlink" title="4.3 Kafka 如何保证不重复消费？"></a>4.3 Kafka 如何保证不重复消费？</h4><p>Kafka 每个消息写进去，都有一个 offset，代表消息的序号，然后 consumer 消费了数据之后，<strong>每隔一段时间</strong>（定时定期），会把自己消费过的消息的 offset 提交一下，表示已经消费过了，下次要重启，继续从上次消费到的 offset 来继续消费。</p>
<p>但是当直接 kill 进程，再重启。这会导致 consumer 有些消息处理了，但是没来得及提交 offset。等重启之后，少数消息就会再次消费一次。</p>
<p><strong>保证消息队列消费的幂等性</strong>：</p>
<p>结合业务，消息可以使用唯一 id 标识。</p>
<ol>
<li>落表（主键或者唯一索引的方式，避免重复数据）</li>
<li>业务逻辑处理（选择唯一主键存储到 Redis 中，先查询是否存在，若存在则不处理；若不存在，先插入 Redis, 再进行业务逻辑处理）</li>
</ol>
<h3 id="5-kafka-的高可靠性实现"><a href="#5-kafka-的高可靠性实现" class="headerlink" title="5. kafka 的高可靠性实现"></a>5. kafka 的高可靠性实现</h3><p>Kafka 0.8 以后，提供了 HA 机制，就是 replica（复制品） 副本机制。每个 partition 的数据都会同步到其它机器上，形成自己的多个 replica 副本。所有 replica 会选举一个 leader 出来，生产和消费都跟这个 leader 打交道，然后其他 replica 就是 follower。写的时候，leader 会负责把数据同步到所有 follower 上去，读的时候就直接读 leader 上的数据即可。另外，Kafka 会均匀地将一个 partition 的所有 replica 分布在不同的机器上，这样才可以提高容错性。</p>
<p><strong>Kafka 的分区多副本架构是 Kafka 可靠性保证的核心，把消息写入多个副本可以使 Kafka 在发生崩溃时仍能保证消息的持久性</strong></p>
<p><strong>写数据</strong>的时候，生产者就写 leader，然后 leader 将数据落地写本地磁盘，接着其他 follower 自己主动从 leader 来 pull 数据。一旦所有 follower 同步好数据了，就会发送 ack 给 leader，leader 收到所有 follower 的 ack 之后，就会返回写成功的消息给生产者。</p>
<p><strong>消费</strong>的时候，只会从 leader 去读，但是只有当一个消息已经被所有 follower 都同步成功返回 ack 的时候，这个消息才会被消费者读到。</p>
<h2 id="Kafka、ActiveMQ、RabbitMQ、RocketMQ-比较"><a href="#Kafka、ActiveMQ、RabbitMQ、RocketMQ-比较" class="headerlink" title="Kafka、ActiveMQ、RabbitMQ、RocketMQ 比较"></a>Kafka、ActiveMQ、RabbitMQ、RocketMQ 比较</h2><div class="table-container">
<table>
<thead>
<tr>
<th>特性</th>
<th>ActiveMQ</th>
<th>RabbitMQ</th>
<th>RocketMQ</th>
<th>Kafka</th>
</tr>
</thead>
<tbody>
<tr>
<td>单机吞吐量</td>
<td>万级，比 RocketMQ、Kafka 低一个数量级</td>
<td>同 ActiveMQ</td>
<td>10 万级，支撑高吞吐</td>
<td>10 万级，高吞吐，一般配合大数据类的系统来进行实时数据计算、日志采集等场景</td>
</tr>
<tr>
<td>topic 数量对吞吐量的影响</td>
<td></td>
<td></td>
<td>topic 可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是 RocketMQ 的一大优势，在同等机器下，可以支撑大量的 topic</td>
<td>topic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，Kafka 尽量保证 topic 数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源</td>
</tr>
<tr>
<td>时效性</td>
<td>ms 级</td>
<td>微秒级，这是 RabbitMQ 的一大特点，延迟最低</td>
<td>ms 级</td>
<td>延迟在 ms 级以内</td>
</tr>
<tr>
<td>可用性</td>
<td>高，基于主从架构实现高可用</td>
<td>同 ActiveMQ</td>
<td>非常高，分布式架构</td>
<td>非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用</td>
</tr>
<tr>
<td>消息可靠性</td>
<td>有较低的概率丢失数据</td>
<td>基本不丢</td>
<td>经过参数优化配置，可以做到 0 丢失</td>
<td>经过参数优化配置，可以做到 0 丢失</td>
</tr>
<tr>
<td>功能支持</td>
<td>MQ 领域的功能极其完备</td>
<td>基于 erlang 开发，并发能力很强，性能极好，延时很低</td>
<td>MQ 功能较为完善，还是分布式的，扩展性好</td>
<td>功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>参考：</p>
<p><a href="https://github.com/doocs/advanced-java" target="_blank" rel="noopener">https://github.com/doocs/advanced-java</a></p>
<p><a href="https://github.com/Dr11ft/BigDataGuide" target="_blank" rel="noopener">https://github.com/Dr11ft/BigDataGuide</a></p>
</blockquote>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://tiantianliu2018.github.io/2020/09/15/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/" data-id="ckf6s58290054xptt4rygfksr"
         class="article-share-link">Share</a>
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Java/" rel="tag">Java</a></li></ul>

    </footer>

  </div>

  
    
  <nav class="article-nav">
    
    
      <a href="/2020/07/05/DQL-Review/" class="article-nav-link">
        <strong class="article-nav-caption">Olde posts</strong>
        <div class="article-nav-title">DQL Review</div>
      </a>
    
  </nav>


  

  
    
  

</article>



</section>
  <footer class="footer">
  <div class="outer">
    <div class="float-right">
      <ul class="list-inline">
  
    <li><i class="fe fe-smile-alt"></i> <span id="busuanzi_value_site_uv"></span></li>
  
</ul>
    </div>
    <ul class="list-inline">
      <li>&copy; 2020 Kelly&#39;s Blogs</li>
      <li>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a></li>
      <li>Theme  <a href="https://github.com/zhwangart/hexo-theme-ocean" target="_blank" rel="noopener">Ocean</a></li>
    </ul>
  </div>
</footer>

</main>
<aside class="sidebar">
  <button class="navbar-toggle"></button>

<nav class="navbar">
  
    <div class="logo">
      <a href="/"><img src="/images/hexo.svg" alt="Kelly&#39;s Blogs"></a>
    </div>
  
  <ul class="nav nav-main">
    
      <li class="nav-item">
        <a class="nav-item-link" href="/">Home</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-item-link" href="/archives">Archives</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-item-link" href="/gallery">Gallery</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-item-link" href="/about">About</a>
      </li>
    
    <li class="nav-item">
      <a class="nav-item-link nav-item-search" title="搜索">
        <i class="fe fe-search"></i>
        Search
      </a>
    </li>
  </ul>
</nav>

<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      <div class="totop" id="totop">
  <i class="fe fe-rocket"></i>
</div>
    </li>
    <li class="nav-item">
      
        <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
          <i class="fe fe-feed"></i>
        </a>
      
    </li>
  </ul>
</nav>

<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
</aside>

<script src="/js/jquery-2.0.3.min.js"></script>


<script src="/js/lazyload.min.js"></script>


<script src="/js/snap.svg-min.js"></script>


<script src="/js/busuanzi-2.3.pure.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>






<script src="/js/ocean.js"></script>


</body>
</html>